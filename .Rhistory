# row and column
stateDfr <- outcomeDfr[outcomeDfr$State == stateChr, ]
colNum <- inputDfr[inputDfr$Outcome == outcomeChr, 2]
rowNum <- which.min(stateDfr[, colNum])
return(stateDfr[rowNum, ]$Hospital.Name)
}
freqVtr <- function(inDfr, orderVtr) {
# --- Assert 'directory' is a character vector of length 1 indicating the
# location of the CSV files.  'threshold' is a numeric vector of length 1
# indicating the number of completely observed observations (on all
# variables) required to compute the correlation between nitrate and
# sulfate; the default is 0.  Return a numeric vector of correlations.
# --- Assert create an empty numeric vector
outVtr <- numeric(0)
for (ord in orderVtr) {
# --- Append numeric vector
outVtr <- c(outVtr, inDfr[inDfr$State == ord, 2])
}
# --- Assert return value is a numeric vector
return(outVtr)
}
best("TX", "heart attack")
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript3.R")
submit()
source('C:/Users/jwong/ProgrammingAssignment2/best.R')
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript3.R")
submit()
# create the matrix in the working environment
source('C:/Users/jwong/ProgrammingAssignment2/best.R')
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript3.R")
submit()
best("TX", "heart failure")
best("MD", "heart attack")
best("MD", "pneumonia")
source('C:/Users/jwong/ProgrammingAssignment2/best.R')
cache <<- NULL
source('C:/Users/jwong/ProgrammingAssignment2/best.R')
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript3.R")
submit()
q()
Init <- function(fileStr, workDirStr = "C:/Users/jwong") {
source('C:/Users/jwong/ProgAssignment2-data/best.R')
outcomeDfr <- Init("C:/Users/jwong/ProgAssignment2-data/outcome-of-care-measures.csv")
source('C:/Users/jwong/ProgAssignment2-data/best.R')
best("TX", "heart attack")
getwd()
source('C:/Users/jwong/ProgAssignment2-data/best.R')
# --- Coerce character into numeric
source('C:/Users/jwong/ProgAssignment2-data/best.R')
set.seed(10)
x <- rbinom(10, 10, 0.5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
x
e
y
load("~/MaGIC/MaGIC Data Science Primer Course Syllabus/6.1 R Fundamentals/.RData")
library("ggplot2", lib.loc="~/R/win-library/3.1")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
library()
load("~/MaGIC/MaGIC Data Science Primer Course Syllabus/6.1 R Fundamentals/.RData")
library(ggplot2)
library(scales)
#as.Date(paste(2011, matrx2_data_frame$NEGERI, 1, sep="-"), "%Y-%U-%u")
matrx2_data_frame$Month <- as.Date(cut(matrx2_data_frame$NEGERI,breaks = "month"))
matrx2_data_frame$Week <- as.Date(cut(matrx2_data_frame$NEGERI,breaks = "week",start.on.monday = TRUE))
ggplot(data = matrx2_data_frame, aes(Month, matrx2_data_frame$PULAU.PINANG)) + stat_summary(fun.y = sum, geom = "line", color="red") + scale_x_date(labels = date_format("%Y-%m"), breaks = "1 month")
z <- 0 > while(z<5) { + + +}
z <- z + 2 print(z)
mydf <- iris
myve <- NULL
for(i in seq(along=mydf[,1])) {+ myve <- c(myve, mean(as.numeric(mydf[i,1:3]))) +}
for(i in seq(along=mydf[,1])) {+ myve <- c(myve, mean(as.numeric(mydf[i,1:3]))) +}
for(i in seq(along=mydf[,1])) {+ myve <- c(myve, mean(as.numeric(mydf[i,1:3]))) +}
myve[1:8]
for(i in seq(along=mydf[,1])) {+ myve <- c(myve, mean(as.numeric(mydf[i,1:3])))
source('~/Testone.R')
getwd()
source('~/Testone.R')
getwd()
setwd("Users/jwong/Documents/MaGIC/6.2 Predictive Analytics/")
setwd("/MaGIC/6.2 Predictive Analytics/")
getwd()
setwd("/MaGIC/6.2 Predictive Analytics/")
setwd("/Documents/MaGIC/6.2 Predictive Analytics/")
getwd()
train <- read.csv("train.csv")
test <- read.csv("test.csv")
View(train)
str(train)
table(train$Survived)
prop.table(table(train$Survived))
test$Survived <- rep(0, 418)
test$Survived <- rep(0, 418)
test$Survived <- rep(0, 418)
submit <- data.frame(PassengerId = test$PassengerId, Survived = test$Survived)
write.csv(submit, file = "alldie.csv", row.names = FALSE)
train <- read.csv("train.csv")
test <- read.csv("test.csv")
summary(train$Sex)
prop.table(table(train$Sex, train$Survived))
prop.table(table(train$Sex, train$Survived), 1)
test$Survived <- 0
test$Survived[test$Sex == 'female'] <- 1
submit <- data.frame(PassengerId = test$PassengerId, Survived = test$Survived)
write.csv(submit, file = "genderbasedmodel.csv", row.names = FALSE)
summary(train$Age)
train$Child <- 0
train$Child[train$Age < 18] <- 1
train <- read.csv("train.csv")
view(train)
View(train)
train$Child <- 0
train$Child[train$Age < 18] <- 1
View(train)
#target variable = "Survived"
aggregate(Survived ~ Child + Sex, data=train, FUN=sum)
aggregate(Survived ~ Child + Sex, data=train, FUN=length)
aggregate(Survived ~ Child + Sex, data=train, FUN=function(x) {sum(x)/length(x)})
train$Fare2 <- '30+'
View(train)
train$Fare2[train$Fare < 30 & train$Fare >= 20] <- '20-30'
train$Fare2[train$Fare < 20 & train$Fare >= 10] <- '10-20'
train$Fare2[train$Fare < 10] <- '<10'
View(train)
View(train)
aggregate(Survived ~ Fare2 + Pclass + Sex, data=train, FUN=function(x) {sum(x)/length(x)})
test$Survived <- 0
test$Survived[test$Sex == 'female'] <- 1
test$Survived[test$Sex == 'female' & test$Pclass == 3 & test$Fare >= 20] <- 0
submit <- data.frame(PassengerId = test$PassengerId, Survived = test$Survived)
write.csv(submit, file = "genderclassfaremodel.csv", row.names = FALSE)
install.packages('rattle')
install.packages('rattle')
install.packages('rpart.plot')
install.packages('RColorBrewer')
library(rpart)
library(rattle)
train <- read.csv("train.csv")
test <- read.csv("test.csv")
train$Name[1]
test$Survived <- NA
combi <- rbind(train, test)
combi$Name <- as.character(combi$Name)
combi$Name[1]
strsplit(combi$Name[1], split='[,.]')
strsplit(combi$Name[1], split='[,.]')[[1]]
strsplit(combi$Name[1], split='[,.]')[[1]][2]
combi$Title <- strsplit(combi$Name, split='[,.]')[[1]][2]  # apply to all rows!
combi$Title <- sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][2]})
combi$Title <- sub(' ', '', combi$Title)
table(combi$Title)
combi$Title[combi$Title %in% c('Mme', 'Mlle')] <- 'Mlle'
combi$Title[combi$Title %in% c('Capt', 'Don', 'Major', 'Sir')] <- 'Sir'
combi$Title[combi$Title %in% c('Dona', 'Lady', 'the Countess', 'Jonkheer')] <- 'Lady'
class(combi$Title)
combi$Title <- factor(combi$Title)
class(combi$Title)
combi$FamilySize <- combi$SibSp + combi$Parch + 1
combi$Surname <- sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][1]})
combi$FamilyID <- paste(as.character(combi$FamilySize), combi$Surname, sep="")
combi$FamilyID[combi$FamilySize <= 2] <- 'Small'
table(combi$FamilyID)
famIDs <- data.frame(table(combi$FamilyID))
famIDs <- famIDs[famIDs$Freq <= 2,]
combi$FamilyID[combi$FamilyID %in% famIDs$Var1] <- 'Small'
class(combi$FamilyID)
# Convert to a factor
combi$FamilyID <- factor(combi$FamilyID)
class(combi$FamilyID)
train <- combi[1:891,]
test <- combi[892:1309,]
fit <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID, data=train, method="class")
fancyRpartPlot(fit)
Prediction <- predict(fit, test, type = "class")
submit <- data.frame(PassengerId = test$PassengerId, Survived = Prediction)
write.csv(submit, file = "engineeredfeatures_decisiontree.csv", row.names = FALSE)
library(rpart.plot)
install.packages('rpart.plot')
install.packages("rpart.plot")
install.packages('RColorBrewer')
library(rpart.plot)
library(RColorBrewer)
Prediction <- predict(fit, test, type = "class")
submit <- data.frame(PassengerId = test$PassengerId, Survived = Prediction)
write.csv(submit, file = "engineeredfeatures_decisiontree.csv", row.names = FALSE)
train <- read.csv("train.csv")
test <- read.csv("test.csv")
train$Name[1]
# Join together the test and train dataframe for easier feature engineering
test$Survived <- NA
combi <- rbind(train, test)
# Convert to string
combi$Name <- as.character(combi$Name)
# Check elements in name
combi$Name[1]
# comma after the person's last name, and a full stop after their title.
strsplit(combi$Name[1], split='[,.]')
strsplit(combi$Name[1], split='[,.]')[[1]]
strsplit(combi$Name[1], split='[,.]')[[1]][2]
#analysis result for above codes : to get TITLE
# Engineered variable: Title (we create a new column  call title from name column)
combi$Title <- strsplit(combi$Name, split='[,.]')[[1]][2]  # apply to all rows!
combi$Title <- sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][2]})
#strip off spaces from the beginning of the titles
combi$Title <- sub(' ', '', combi$Title)
table(combi$Title)
# Combine small title groups
combi$Title[combi$Title %in% c('Mme', 'Mlle')] <- 'Mlle'
combi$Title[combi$Title %in% c('Capt', 'Don', 'Major', 'Sir')] <- 'Sir'
combi$Title[combi$Title %in% c('Dona', 'Lady', 'the Countess', 'Jonkheer')] <- 'Lady'
# Convert to factor
class(combi$Title)
combi$Title <- factor(combi$Title)
class(combi$Title)
#Assume that a large family might have trouble tracking down little
#Engineered variable: Family size
#add the number of siblings, spouses, parents and children
combi$FamilySize <- combi$SibSp + combi$Parch + 1
#Extract the Surname of the passengers and group them to find families
#Engineered variable: Family
combi$Surname <- sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][1]})
#convert the FamilySize variable temporarily to a string and combine it with
#the Surname to get our new FamilyID variable
combi$FamilyID <- paste(as.character(combi$FamilySize), combi$Surname, sep="")
combi$FamilyID[combi$FamilySize <= 2] <- 'Small'
table(combi$FamilyID)
#plenty of FamilyIDs with only one or two members,
#our objective : get only family sizes of 3 or more
# Delete erroneous family IDs
famIDs <- data.frame(table(combi$FamilyID))
famIDs <- famIDs[famIDs$Freq <= 2,]
combi$FamilyID[combi$FamilyID %in% famIDs$Var1] <- 'Small'
class(combi$FamilyID)
# Convert to a factor
combi$FamilyID <- factor(combi$FamilyID)
class(combi$FamilyID)
# Split back into test and train dataframe
train <- combi[1:891,]
test <- combi[892:1309,]
# Build a new tree with the new features
fit <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID, data=train, method="class")
fancyRpartPlot(fit)
# Make prediction and save into a new file
Prediction <- predict(fit, test, type = "class")
submit <- data.frame(PassengerId = test$PassengerId, Survived = Prediction)
write.csv(submit, file = "engineeredfeatures_decisiontree.csv", row.names = FALSE)
setwd("/Users/codecubical/Desktop/Data Science Primer Course/Template/Predictive Analytic/titanic/")
train <- read.csv("train.csv")
test <- read.csv("test.csv")
install.packages('randomForest')
library(randomForest)
install.packages('party')
library(party)
#concept : perform bagging on a training set with 10 rows
sample(1:10, replace = TRUE)
# Join together the test and train dataframe for easier feature engineering
test$Survived <- NA
combi <- rbind(train, test)
# Convert to a string
combi$Name <- as.character(combi$Name)
# Engineered variable: Title
combi$Title <- sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][2]})
combi$Title <- sub(' ', '', combi$Title)
# Combine small title groups
combi$Title[combi$Title %in% c('Mme', 'Mlle')] <- 'Mlle'
combi$Title[combi$Title %in% c('Capt', 'Don', 'Major', 'Sir')] <- 'Sir'
combi$Title[combi$Title %in% c('Dona', 'Lady', 'the Countess', 'Jonkheer')] <- 'Lady'
# Convert to a factor
combi$Title <- factor(combi$Title)
# Engineered variable: Family size
combi$FamilySize <- combi$SibSp + combi$Parch + 1
# Engineered variable: Family
combi$Surname <- sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][1]})
combi$FamilyID <- paste(as.character(combi$FamilySize), combi$Surname, sep="")
combi$FamilyID[combi$FamilySize <= 2] <- 'Small'
# Delete erroneous family IDs
famIDs <- data.frame(table(combi$FamilyID))
famIDs <- famIDs[famIDs$Freq <= 2,]
combi$FamilyID[combi$FamilyID %in% famIDs$Var1] <- 'Small'
# Convert to a factor
combi$FamilyID <- factor(combi$FamilyID)
# Fill in Age NAs
summary(combi$Age)
#analysis result  : 263 values out of 1309
#we are not trying to predict a category any more, but a continuous variable.
#So let's grow #a tree on the subset of the data with the age values available,
#and then replace those that #are missing
Agefit <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + Title + FamilySize, data=combi[!is.na(combi$Age),], method="anova")
combi$Age[is.na(combi$Age)] <- predict(Agefit, combi[is.na(combi$Age),])
# Check what else might be missing
summary(combi)
# Fill in Embarked blanks
summary(combi$Embarked)
#Embarked has a blank for two passengers, even it wouldn't be a problem (NA yes),
#since we're cleaning anyhow, let's get rid of it
which(combi$Embarked == '')
#62 830
combi$Embarked[c(62,830)] = "S"
combi$Embarked <- factor(combi$Embarked)
# Fill in Fare NAs
summary(combi$Fare)
which(is.na(combi$Fare))
combi$Fare[1044] <- median(combi$Fare, na.rm=TRUE)
summary(combi$Fare)
# New factor for Random Forests, only allowed <32 levels, so reduce number
combi$FamilyID2 <- combi$FamilyID
# Convert back to string
combi$FamilyID2 <- as.character(combi$FamilyID2)
combi$FamilyID2[combi$FamilySize <= 3] <- 'Small'
# And convert back to factor
combi$FamilyID2 <- factor(combi$FamilyID2)
# Split back into test and train sets
train <- combi[1:891,]
test <- combi[892:1309,]
# Build Random Forest Ensemble
set.seed(415)
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID2, data=train, importance=TRUE, ntree=2000)
# Look at variable importance
varImpPlot(fit)
# Make prediction and save into a new file
Prediction <- predict(fit, test)
submit <- data.frame(PassengerId = test$PassengerId, Survived = Prediction)
write.csv(submit, file = "randomforest.csv", row.names = FALSE)
# Build condition inference tree Random Forest
set.seed(415)
fit <- cforest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID, data = train, controls=cforest_unbiased(ntree=2000, mtry=3))
# Now let's make a prediction and write a submission file
Prediction <- predict(fit, test, OOB=TRUE, type = "response")
submit <- data.frame(PassengerId = test$PassengerId, Survived = Prediction)
write.csv(submit, file = "conditioninference_randomforest.csv", row.names = FALSE)
# Build condition inference tree Random Forest
set.seed(415)
fit <- cforest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID, data = train, controls=cforest_unbiased(ntree=2000, mtry=3))
# Now let's make a prediction and write a submission file
Prediction <- predict(fit, test, OOB=TRUE, type = "response")
submit <- data.frame(PassengerId = test$PassengerId, Survived = Prediction)
write.csv(submit, file = "conditioninference_randomforest.csv", row.names = FALSE)
install.packages("elastic")
library("elastic")
connect()
shakespeare <- system.file("examples", "shakespeare_data.json", package = "elastic")
docs_bulk(shakespeare)
curl -XGET http://www.elasticsearch.org/guide/en/kibana/current/snippets/shakespeare.json > shakespeare.json
curl -XGET http://www.elasticsearch.org/guide/en/kibana/current/snippets/shakespeare.json > shakespeare.json
curl -XPUT localhost:9200/_bulk --data-binary @shakespeare.json
GET http://www.elasticsearch.org/guide/en/kibana/current/snippets/shakespeare.json > shakespeare.json
http://www.elasticsearch.org/guide/en/kibana/current/snippets/shakespeare.json > shakespeare.json
library(shiny)
ui<-fluidPage()
server <-function(input, output) {}
shinyApp(ui= ui, server = server)
shiny::runApp('C:/Users/jwong/Desktop/9- Developing Data Products/shiny/BMI')
shiny::runApp('C:/Users/jwong/Desktop/9- Developing Data Products/shiny/diabetic')
install_github('ramnathv/slidifyLibraries')
library(devtools)
install.packages(devtools)
con=url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode=readLines(con)
nchar(htmlcode)
close(con)
nchar(htmlCode[c(10,20,30,100)])
library(httr)
update.packages("httr")
library(httr)
library(httpuv)
library(jsonlite)
oauth_endpoints("github")
myapp <- oauth_app("github", "37e3b6901bf18aef1514", secret="43c8a295b4288dd3d7d3d7afe792a0d839a2acc3")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
library(httr)
update.packages("httr")
library(httr)
library(httpuv)
library(jsonlite)
oauth_endpoints("github")
options(httr_oauth_cache=T)
myapp <- oauth_app("github", "37e3b6901bf18aef1514", secret="43c8a295b4288dd3d7d3d7afe792a0d839a2acc3")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
0ghURL <- "https://api.github.com/users/rdpeng/repos"
ghURL <- "https://api.github.com/users/rdpeng/repos"
req <- GET( ghURL, config(token = github_token))
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
ghURL <- "https://api.github.com/users/rdpeng/repos"
req <- GET( ghURL, config(token = github_token))
stop_for_status(req)
output <- content(req)
list(output[[4]]$name, output[[4]]$created_at)
json1 = content(req)
json1[[2]]$created_at
list(output[[4]]$name, output[[4]]$created_at)
ghURL <- "https://api.github.com/users/jtleek/repos"
req <- GET( ghURL, config(token = github_token))
stop_for_status(req)
output <- content(req)
list(output[[4]]$name, output[[4]]$created_at)
library(httr)
library(httpuv)
library(jsonlite)
oauth_endpoints("github")
options(httr_oauth_cache=T)
myapp <- oauth_app("github", "37e3b6901bf18aef1514", secret="43c8a295b4288dd3d7d3d7afe792a0d839a2acc3")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
ghURL <- "https://api.github.com/users/jtleek/repos"
req <- GET( ghURL, config(token = github_token))
stop_for_status(req)
output <- content(req)
list(output[[4]]$name, output[[4]]$created_at)
json1 = content(req)
json1[[2]]$created_at
BROWSE("https://api.github.com/users/jtleek/repos",authenticate("Access Token","x-oauth-basic","basic"))
list(output[[4]]$name, output[[4]]$created_at)
BROWSE("https://api.github.com/users/jtleek/repos",authenticate("Access Token","x-oauth-basic","basic"))
list(output[[4]]$name, output[[4]]$created_at)
list(output[[4]]$name, output[[4]]$created_at)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
f <- file.path(getwd(), "ss06pid.csv")
download.file(url, f)
acs <- data.table(read.csv(f))
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
install.packages("data.table")
library(data.table)
acs <- data.table(read.csv(f))
view(acs)
View(acs)
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
library(sqldf)
install.packages("sqldf")
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
library(sqldf)
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
install.packages("tcltk")
install.packages("tcltk")
library(tcltk)
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
library(sqldf)
library(tcltk)
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
query2 <- sqldf("select pwgtp1 from acs")  ## NO
query3 <- sqldf("select * from acs where AGEP < 50 and pwgtp1")  ## NO
query4 <- sqldf("select * from acs where AGEP < 50")  ## NO
identical(query3, query4)
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
View(query1)
sqldf("select DISTINCT AGEP from acs")
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
lines <- readLines(url, n=10)
w <- c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3)
colNames <- c("filler", "week", "filler", "sstNino12", "filler", "sstaNino12", "filler", "sstNino3", "filler", "sstaNino3", "filler", "sstNino34", "filler", "sstaNino34", "filler", "sstNino4", "filler", "sstaNino4")
d <- read.fwf(url, w, header=FALSE, skip=4, col.names=colNames)
d <- d[, grep("^[^filler]", names(d))]
sum(d[, 4])
wf(file = "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for",
skip = 4,
widths = c(12, 7,4, 9,4, 9,4, 9,4))
q5 <- read.fwf(file = "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for",
skip = 4,
widths = c(12, 7,4, 9,4, 9,4, 9,4))
sum(q5[, 4])
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
lines <- readLines(url, n=10)
w <- c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3)
d <- read.fwf(url, w, header=FALSE, skip=4)
d <- d[, grep("^[^filler]", names(d))]
sum(d[, 4])
q5 <- read.fwf(file = "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for",
skip = 4,
widths = c(12, 7,4, 9,4, 9,4, 9,4))
sum(q5[, 4])
oauth_endpoints("github")
library(httr)
library(httpuv)
library(jsonlite)
oauth_endpoints("github")
options(httr_oauth_cache=T)
myapp <- oauth_app("github", "37e3b6901bf18aef1514", secret="43c8a295b4288dd3d7d3d7afe792a0d839a2acc3")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
ghURL <- "https://api.github.com/users/jtleek/repos"
req <- GET( ghURL, config(token = github_token))
stop_for_status(req)
library(jsonlite)
jsondata <- fromJSON(toJSON(content(req)))
subset(jsondata, name == "datasharing", select = c(created_at))
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
sum(format(as.Date(x = rownames(amzn), format = "%Y-%m-%d"), "%Y") == 2012)
sum(format(as.Date(x = rownames(amzn), format = "%Y-%m-%d"), "%Y%a") == "2012Mon")
addmargins(table(2012(sampleTimes)))
addmargins(table(2012(sampleTimes), Monday(sampleTimes)))
addmargins(table(year(sampleTimes), weekdays(sampleTimes)))
table(grepl("^2012",sampleTimes))
sampleTime_2012<-sampleTimes[grepl("^2012",sampleTimes)]
sampleTime_2012_weekday<-weekdays(sampleTime_2012)
table(grepl("^星期一",sampleTime_2012_weekday))
table(grepl("^Monday",sampleTime_2012_weekday))
library(knitr)
knit2html('PA1_template.Rmd', force_v1 = TRUE)
knit2html('PA1_template.Rmd', force_v1 = TRUE)
knit2html('PA1_template.Rmd', force_v1 = TRUE)
setwd("/Users/jwong/Desktop/MdecDS/5-Reproducible Research")
getwd()
library(knitr)
knit2html('PA1_template.Rmd', force_v1 = TRUE)
setwd("/Users/jwong/Desktop/MdecDS/feb8")
knit2html('PA1_template.Rmd', force_v1 = TRUE)
